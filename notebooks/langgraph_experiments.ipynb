{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Experiments\n",
    "\n",
    "This notebook demonstrates how to use LangGraph for building AI agents. We'll explore:\n",
    "1. Basic graph setup\n",
    "2. State management\n",
    "3. Node creation\n",
    "4. Edge configuration\n",
    "5. Running the graph\n",
    "6. Streaming outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from typing import TypeVar, List\n",
    "from typing_extensions import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "from agents.llmtools import get_llm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define State and Models\n",
    "\n",
    "First, let's define our state type and any Pydantic models we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskState(TypedDict):\n",
    "    \"\"\"State for our simple task graph\"\"\"\n",
    "    task: str  # The task to complete\n",
    "    steps: List[str]  # Steps to complete the task\n",
    "    current_step: str  # Current step being worked on\n",
    "    result: str  # Final result\n",
    "\n",
    "class StepList(BaseModel):\n",
    "    \"\"\"Model for task steps\"\"\"\n",
    "    steps: List[str] = Field(description=\"List of steps to complete the task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph Nodes\n",
    "\n",
    "Now let's create some nodes for our graph. Each node will be a function that processes the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state type\n",
    "workflow_state = TypeVar(\"workflow_state\", bound=TaskState)\n",
    "\n",
    "def plan_steps(state: workflow_state) -> workflow_state:\n",
    "    \"\"\"Break down the task into steps\"\"\"\n",
    "    llm = get_llm()\n",
    "    prompt = f\"Break down this task into 3-5 concrete steps: {state['task']}\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(StepList)\n",
    "    response = structured_llm.invoke(prompt)\n",
    "    \n",
    "    state[\"steps\"] = response.steps\n",
    "    state[\"current_step\"] = response.steps[0]\n",
    "    return state\n",
    "\n",
    "def execute_step(state: workflow_state) -> workflow_state:\n",
    "    \"\"\"Execute the current step\"\"\"\n",
    "    llm = get_llm()\n",
    "    prompt = f\"Execute this step and provide the result: {state['current_step']}\"\n",
    "    \n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"result\"] = result\n",
    "    \n",
    "    # Move to next step if available\n",
    "    current_index = state[\"steps\"].index(state[\"current_step\"])\n",
    "    if current_index < len(state[\"steps\"]) - 1:\n",
    "        state[\"current_step\"] = state[\"steps\"][current_index + 1]\n",
    "    \n",
    "    return state\n",
    "\n",
    "def end(state: workflow_state) -> workflow_state:\n",
    "    \"\"\"Final node to complete the workflow\"\"\"\n",
    "    print(\"Task completed with result:\", state[\"result\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Configure the Graph\n",
    "\n",
    "Now we'll create our graph, add nodes, and configure edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_graph():\n",
    "    # Create the graph\n",
    "    workflow = StateGraph(TaskState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"plan\", plan_steps)\n",
    "    workflow.add_node(\"execute\", execute_step)\n",
    "    workflow.add_node(\"__END__\", end)\n",
    "    \n",
    "    # Create edges\n",
    "    workflow.add_edge(\"plan\", \"execute\")\n",
    "    workflow.add_edge(\"execute\", \"execute\")\n",
    "    workflow.add_edge(\"execute\", \"__END__\")\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"plan\")\n",
    "    \n",
    "    # Compile graph\n",
    "    return workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Create the graph\n",
    "task_graph = create_task_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Graph\n",
    "\n",
    "Let's try running our graph with a sample task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "initial_state: TaskState = {\n",
    "    \"task\": \"Write a short blog post about AI agents\",\n",
    "    \"steps\": [],\n",
    "    \"current_step\": \"\",\n",
    "    \"result\": \"\"\n",
    "}\n",
    "\n",
    "# Run the graph\n",
    "final_state = await task_graph.arun(initial_state)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal State:\")\n",
    "print(\"Steps:\", final_state[\"steps\"])\n",
    "print(\"Result:\", final_state[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Results\n",
    "\n",
    "Now let's see how to stream results from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in task_graph.astream(initial_state):\n",
    "    print(\"Event:\", event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
